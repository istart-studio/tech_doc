= Amdahl's law 阿姆达定律

https://en.wikipedia.org/wiki/Amdahl%27s_law

== 须知
阿姆达尔定律只能用在固定范围的问题上面。在实际中，随着可用的计算资源越来越多，这些资源倾向于用于更大的问题上面（更大的数据集），而且并行部分上的时间开销通常比串行工作增长要快。在这样的情况下，(Gustafson’s law)古斯塔夫森定律给出了更佳的接近实际的针对并行计算性能的评估

== 推导

一个任务由p + (1-p) 构成。

p:可根据资源提升而得到加速的部分

1-p:不可通过资源提升而得到加速的部分

任务时间：T = (1-p)T + pT

s:加速比,加速后的执行时间 p/s  T。

加速比越高说明你的优化越明显

加速后的总执行时间：T(s)=(1-p)T + (p/s)T

优化前系统消耗时/优化后系统消耗时

S~latency~(s) = TW/T(s)W = T/T(s) = 1 / (1-p) + p/s

== 收益递减

如果选择了最佳的部分来提速，那么我们会看到随着资源的进一步提升，获得的加速是单调递减的。如果选择的不是最优，那么继续提升最关键部分还是能看到明显的提高。注意实际情况中，这种通过改善非最优部件来提升系统性能的事情是合理的，因为提升关键部分常常会更加困难，或者花费更多时间。

如果你是在运行一个固定计算量的程，而且正在考虑随着机器处理核心数量的增加伴随而来的收益，那么阿姆达尔定律确实展现了边际递减。每个新增加的处理器带来的性能比前一个处理器带来的要小。每次处理核心数加倍，加速比减小，最终趋向于1/(1-p)。

这样的分析忽略了其他潜在的瓶颈，例如内存带宽和I/O带宽，如果它们不随这核心数目提升，那么把这些瓶颈考虑进去更加显现了纯粹通过增加处理器所具有的边际递减规律。

SpeedUp =< 1 / (F + (1-F)/N )